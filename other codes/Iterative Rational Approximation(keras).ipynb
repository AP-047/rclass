{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c18ffab-058d-4567-931d-27b36b224dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Start timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5292f05c-4861-45fe-a207-42c681810e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 08:41:03.924669: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-22 08:41:03.933029: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 08:41:03.940631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 08:41:03.942740: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-22 08:41:03.948372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from functools import wraps\n",
    "from sage.all import *\n",
    "from sage.numerical.mip import MIPSolverException\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ceb9498-15a9-4f1c-94c6-7befedbcb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"[TIME] {func.__name__} took {end - start:.3f} s\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57771dac-3e19-4d80-a88d-3ceeafeb4de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(N_samples=500, test_size=0.2, random_state=42):\n",
    "    # Load the MNIST dataset\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Optionally, combine train and test sets if you want to resplit\n",
    "    X = np.concatenate((X_train, X_test), axis=0)\n",
    "    y = np.concatenate((y_train, y_test), axis=0)\n",
    "    \n",
    "    # Subsample if N_samples is less than the total number of samples\n",
    "    if N_samples < len(X):\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        idx = rng.choice(len(X), N_samples, replace=False)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=float(test_size), random_state=random_state\n",
    "    )\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], -1)\n",
    "    y_test = y_test.reshape(y_test.shape[0], -1)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def preprocess_data(X_train, X_test, pca_dims=5):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    if pca_dims > 0:\n",
    "        pca = PCA(n_components=pca_dims)\n",
    "        X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "        X_test_pca  = pca.transform(X_test_scaled)\n",
    "    else:\n",
    "        # if pca_dims=0, skip PCA\n",
    "        X_train_pca = X_train_scaled\n",
    "        X_test_pca  = X_test_scaled\n",
    "        pca = None\n",
    "\n",
    "    return X_train_pca, X_test_pca, scaler, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac464b22-79ba-4558-8281-9db4332f0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exponents(d, n):\n",
    "    \"\"\"\n",
    "    Generates all tuples (a_1,...,a_d) of non-negative integers\n",
    "    with a_1+...+a_d <= n.\n",
    "    \"\"\"\n",
    "    # Simple recursive or iterative approach\n",
    "    # For example, if d=2, n=2: (0,0), (1,0), (0,1), (2,0), (1,1), (0,2)\n",
    "    # We'll do a small recursive generator:\n",
    "    def recurse(dim, maxdeg, current):\n",
    "        if dim==0:\n",
    "            yield tuple(current)\n",
    "        else:\n",
    "            # we can put up to maxdeg in position 0..n\n",
    "            for a in range(maxdeg+1):\n",
    "                # next dimension can have up to leftover\n",
    "                curr_copy = current[:]\n",
    "                curr_copy.append(a)\n",
    "                yield from recurse(dim-1, maxdeg, curr_copy)\n",
    "    # That yields all combos a_1..a_d each in [0..n], sum not constrained\n",
    "    # We need to filter sum(a_j)<=n\n",
    "    all_tuples = recurse(d, n, [])\n",
    "    for t in all_tuples:\n",
    "        if sum(t)<=n:\n",
    "            yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669c6ae5-319f-46d7-9989-9e6c77cb9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_partial_poly_matrix(X, n):\n",
    "    \"\"\"\n",
    "    Builds partial polynomial features up to total degree <= n\n",
    "    for each row in X (shape: (N,d)).\n",
    "    Returns: shape (N, #monomials).\n",
    "    \"\"\"\n",
    "    N,d = X.shape\n",
    "    exps = list(generate_exponents(d, n))\n",
    "    # exps is a list of exponent tuples (a_1,...,a_d)\n",
    "    # We'll build features of size (#exps).\n",
    "    M = len(exps)\n",
    "    mat = np.zeros((N, M), dtype=np.float64)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j,(a_tuple) in enumerate(exps):\n",
    "            # compute x_1^a1 * x_2^a2 * ...\n",
    "            val = 1.0\n",
    "            for dim_idx, alpha in enumerate(a_tuple):\n",
    "                if alpha>0:\n",
    "                    val *= (X[i, dim_idx] ** alpha)\n",
    "            mat[i,j] = val\n",
    "    return mat, exps  # we return exps if we need to evaluate single points later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98de84e-a198-4cd1-9f98-e6370100584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def solve_minmax_p(Xp, Xq, f_values, q_coeffs, z_bound=1.0):\n",
    "    \"\"\"\n",
    "    Solve for p-coeffs in a min-max sense, with q fixed.\n",
    "    We do: |f_i - p(x_i)/q(x_i)| <= z_bound\n",
    "    => (f_i - z_bound)*q_i <= p_i <= (f_i + z_bound)*q_i\n",
    "    => We'll treat z_bound as known, or do a small bisection if needed.\n",
    "\n",
    "    Here p(x_i) = Xp[i,:]^T p_coeffs\n",
    "         q(x_i) = Xq[i,:]^T q_coeffs  (already known from previous iteration)\n",
    "    \"\"\"\n",
    "    N = len(f_values)\n",
    "    p_dim = Xp.shape[1]\n",
    "\n",
    "    # We'll do a linear feasibility check for p_coeffs:\n",
    "    p_lp = MixedIntegerLinearProgram(maximization=False, solver=\"GLPK\")\n",
    "    v = p_lp.new_variable(real=True)\n",
    "\n",
    "    # For each i:\n",
    "    # define p_i = sum_{k=0..p_dim-1} Xp[i,k]*v[k]\n",
    "    # define q_i = sum_{r=0..q_dim-1} Xq[i,r]*q_coeffs[r] (this is known, no variable)\n",
    "    # so constraints: p_i >= (f_i - z_bound)*q_i\n",
    "    #                p_i <= (f_i + z_bound)*q_i\n",
    "    for i in range(N):\n",
    "        f_i = f_values[i]\n",
    "        lhs_p = sum(Xp[i,k]*v[k] for k in range(p_dim))\n",
    "        q_val = 0.0\n",
    "        for r,c_val in enumerate(q_coeffs):\n",
    "            q_val += c_val*Xq[i,r]\n",
    "\n",
    "        p_lp.add_constraint(lhs_p - (f_i - z_bound)*q_val >= 0)\n",
    "        p_lp.add_constraint(lhs_p - (f_i + z_bound)*q_val <= 0)\n",
    "\n",
    "    # just solve feasibility\n",
    "    try:\n",
    "        p_lp.solve()\n",
    "        p_sol = np.array([p_lp.get_values(v[k]) for k in range(p_dim)])\n",
    "        return True, p_sol\n",
    "    except MIPSolverException:\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c56e81e-3819-4770-9f8f-c01a96e51652",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def solve_minmax_q(Xp, Xq, f_values, p_coeffs, z_bound=1.0, DLB=1e-3, DUB=1e3):\n",
    "    \"\"\"\n",
    "    Solve for q-coeffs in a min-max sense, with p fixed.\n",
    "    |f_i - p_i/q_i| <= z_bound\n",
    "    => (f_i - z_bound)*q_i <= p_i <= (f_i + z_bound)*q_i\n",
    "    => DLB <= q_i <= DUB\n",
    "    We'll do a linear feasibility for q_coeffs if we fix p_i.\n",
    "\n",
    "    p_i = Xp[i,:]^T p_coeffs (known)\n",
    "    q_i = Xq[i,:]^T q_vars\n",
    "    \"\"\"\n",
    "    N = len(f_values)\n",
    "    q_dim = Xq.shape[1]\n",
    "\n",
    "    q_lp = MixedIntegerLinearProgram(maximization=False, solver=\"GLPK\")\n",
    "    v = q_lp.new_variable(real=True)\n",
    "\n",
    "    # Optionally fix e.g. q_0=1 => to avoid trivial solutions\n",
    "    # We demonstrate that approach:\n",
    "    q_lp.add_constraint(v[0] == 1)\n",
    "\n",
    "    for i in range(N):\n",
    "        f_i = f_values[i]\n",
    "        p_val = np.dot(p_coeffs, Xp[i,:])  # known\n",
    "        lhs_q = sum(Xq[i,r]*v[r] for r in range(q_dim))\n",
    "\n",
    "        q_lp.add_constraint( p_val - (f_i - z_bound)*lhs_q >= 0 )\n",
    "        q_lp.add_constraint( p_val - (f_i + z_bound)*lhs_q <= 0 )\n",
    "        # DLB <= lhs_q <= DUB\n",
    "        q_lp.add_constraint(lhs_q >= DLB)\n",
    "        q_lp.add_constraint(lhs_q <= DUB)\n",
    "\n",
    "    try:\n",
    "        q_lp.solve()\n",
    "        q_sol = np.array([q_lp.get_values(v[r]) for r in range(q_dim)])\n",
    "        return True, q_sol\n",
    "    except MIPSolverException:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23bd21e2-c394-46f6-be85-816b4c61d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def train_iterative_rational_oneclass(X, f_values, n_p=2, n_q=1,\n",
    "                                      max_samples=300,\n",
    "                                      max_iter=10,\n",
    "                                      z_bound=0.5,\n",
    "                                      DLB=1e-3, DUB=1e3):\n",
    "    \"\"\"\n",
    "    X: (N, d) data for a single class,  f_values in {0,1}.\n",
    "    We'll do partial polynomials for p, q up to total degrees n_p, n_q.\n",
    "\n",
    "    Steps:\n",
    "      1) Sub-sample if needed\n",
    "      2) Build partial expansions Xp, Xq\n",
    "      3) Initialize q(x)=1 => q_coeffs = [1,0,0...]\n",
    "      4) Alternate solve for p, solve for q, for max_iter steps\n",
    "      5) Return final p_coeffs, q_coeffs\n",
    "    \"\"\"\n",
    "    N = len(f_values)\n",
    "    if max_samples < N:\n",
    "        idx = np.random.choice(N, max_samples, replace=False)\n",
    "        X_sub = X[idx]\n",
    "        f_sub = f_values[idx]\n",
    "    else:\n",
    "        X_sub = X\n",
    "        f_sub = f_values\n",
    "\n",
    "    # Build expansions\n",
    "    Xp, exps_p = build_partial_poly_matrix(X_sub, n_p)\n",
    "    Xq, exps_q = build_partial_poly_matrix(X_sub, n_q)\n",
    "\n",
    "    p_dim = Xp.shape[1]\n",
    "    q_dim = Xq.shape[1]\n",
    "\n",
    "    # init q_coeffs => fix q_0=1, rest=0\n",
    "    q_coeffs = np.zeros(q_dim)\n",
    "    q_coeffs[0] = 1.0\n",
    "\n",
    "    # Iterative approach\n",
    "    p_coeffs = np.zeros(p_dim)\n",
    "    for it in range(max_iter):\n",
    "        # Step A: Solve for p with q fixed\n",
    "        feasible_p, p_new = solve_minmax_p(Xp, Xq, f_sub, q_coeffs, z_bound)\n",
    "        if not feasible_p:\n",
    "            print(\"No feasible p found in iteration\", it)\n",
    "            return None, None\n",
    "\n",
    "        # Step B: Solve for q with p fixed\n",
    "        feasible_q, q_new = solve_minmax_q(Xp, Xq, f_sub, p_new, z_bound, DLB, DUB)\n",
    "        if not feasible_q:\n",
    "            print(\"No feasible q found in iteration\", it)\n",
    "            return None, None\n",
    "\n",
    "        p_coeffs = p_new\n",
    "        q_coeffs = q_new\n",
    "\n",
    "    # Done\n",
    "    return p_coeffs, q_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56a00b77-8bdc-4063-8dcd-2f1d3389c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_point_rational(x, p_coeffs, q_coeffs, exps_p, exps_q):\n",
    "    \"\"\"\n",
    "    Evaluate p(x)/q(x) at a single point x, given partial expansions exps_p, exps_q.\n",
    "    \"\"\"\n",
    "    # Build partial polynomial for x in the same manner as build_partial_poly_matrix\n",
    "    # We'll do a direct function for that:\n",
    "    px = 1.0\n",
    "    p_val = 0.0\n",
    "    q_val = 0.0\n",
    "\n",
    "    # For p:\n",
    "    # p_val = sum_{j} p_coeffs[j] * x^{exps_p[j]}\n",
    "    # We'll do it directly:\n",
    "    monomials_p = 1.0\n",
    "    p_val = 0.0\n",
    "    for j, a_tuple in enumerate(exps_p):\n",
    "        val = 1.0\n",
    "        for dim_i, alpha in enumerate(a_tuple):\n",
    "            if alpha>0:\n",
    "                val *= x[dim_i]**alpha\n",
    "        p_val += p_coeffs[j]*val\n",
    "\n",
    "    # For q:\n",
    "    monomials_q = 1.0\n",
    "    q_val = 0.0\n",
    "    for j, a_tuple in enumerate(exps_q):\n",
    "        val = 1.0\n",
    "        for dim_i, alpha in enumerate(a_tuple):\n",
    "            if alpha>0:\n",
    "                val *= x[dim_i]**alpha\n",
    "        q_val += q_coeffs[j]*val\n",
    "\n",
    "    if abs(q_val)<1e-12:\n",
    "        return 1e9 if p_val>0 else -1e9\n",
    "    return p_val/q_val\n",
    "\n",
    "def predict_binary_approx(x, p_coeffs, q_coeffs, exps_p, exps_q, threshold=0.5):\n",
    "    val = evaluate_point_rational(x, p_coeffs, q_coeffs, exps_p, exps_q)\n",
    "    return 1 if val>threshold else 0\n",
    "\n",
    "def accuracy_approx(X, f_values, p_coeffs, q_coeffs, exps_p, exps_q, threshold=0.5):\n",
    "    correct=0\n",
    "    for i in range(len(X)):\n",
    "        pred = predict_binary_approx(X[i], p_coeffs, q_coeffs, exps_p, exps_q, threshold)\n",
    "        if pred == f_values[i]:\n",
    "            correct+=1\n",
    "    return correct/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87adb67d-06e0-48b2-89e7-4eeb95102151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ova_iterative(X_train, y_train, X_test, y_test,\n",
    "                        n_p=2, n_q=1, pca_dims=5,\n",
    "                        max_samples=300,\n",
    "                        z_bound=0.5,\n",
    "                        DLB=1e-3, DUB=1e3):\n",
    "    \"\"\"\n",
    "    For digits [0..9], do:\n",
    "      1) build f_c, in {0,1}\n",
    "      2) train iterative approach => p_coeffs, q_coeffs\n",
    "      3) store in models[c]\n",
    "    Then test multi-class by picking the largest p_c(x)/q_c(x).\n",
    "\n",
    "    Return (models, exps_p, exps_q).\n",
    "    \"\"\"\n",
    "    # We'll do partial polynomial expansions in the original or PCA space\n",
    "    # For demonstration, let's do a PCA outside this function if you want to.\n",
    "\n",
    "    # Actually let's do it here for completeness\n",
    "    # (But if you already have X_train_pca, just skip PCA here.)\n",
    "    # We'll assume X_train, X_test are already scaled => optional\n",
    "    # For clarity we skip PCA if pca_dims=0, or do it if > 0\n",
    "    # *** If you do want to do it externally, just remove these lines.\n",
    "    if pca_dims>0:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_sc = scaler.fit_transform(X_train)\n",
    "        X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=pca_dims)\n",
    "        X_train_pca = pca.fit_transform(X_train_sc)\n",
    "        X_test_pca  = pca.transform(X_test_sc)\n",
    "    else:\n",
    "        X_train_pca = X_train\n",
    "        X_test_pca  = X_test\n",
    "\n",
    "    # We'll store: models[c] = (p_coeffs, q_coeffs, exps_p, exps_q)\n",
    "    models = {}\n",
    "\n",
    "    # Create per-class data\n",
    "    for c in range(10):\n",
    "        # f_c\n",
    "        f_c = np.array([1 if lbl==c else 0 for lbl in y_train])\n",
    "\n",
    "        # Train\n",
    "        p_coeffs, q_coeffs = train_iterative_rational_oneclass(\n",
    "            X_train_pca, f_c, n_p, n_q, max_samples=max_samples,\n",
    "            z_bound=z_bound, DLB=DLB, DUB=DUB\n",
    "        )\n",
    "        if p_coeffs is None:\n",
    "            print(f\"Class {c} => No feasible solution.\")\n",
    "            models[c] = None\n",
    "            continue\n",
    "\n",
    "        # We'll keep expansions for p,q for evaluating new points:\n",
    "        _, exps_p = build_partial_poly_matrix(X_train_pca[:1], n_p)\n",
    "        _, exps_q = build_partial_poly_matrix(X_train_pca[:1], n_q)\n",
    "\n",
    "        # Evaluate train accuracy quickly\n",
    "        train_acc = accuracy_approx(X_train_pca, f_c, p_coeffs, q_coeffs, exps_p, exps_q)\n",
    "        print(f\"[OvA] Class {c}: train_acc={float(train_acc)}\")\n",
    "\n",
    "        models[c] = (p_coeffs, q_coeffs, exps_p, exps_q)\n",
    "\n",
    "    # Evaluate multi-class on test\n",
    "    test_preds = []\n",
    "    for i in range(len(X_test_pca)):\n",
    "        x = X_test_pca[i]\n",
    "        best_class = None\n",
    "        best_val   = -1e12\n",
    "        for c in range(10):\n",
    "            if models[c] is None:\n",
    "                continue\n",
    "            pcf, qcf, ep, eq = models[c]\n",
    "            val_c = evaluate_point_rational(x, pcf, qcf, ep, eq)\n",
    "            if val_c>best_val:\n",
    "                best_val=val_c\n",
    "                best_class=c\n",
    "        test_preds.append(best_class)\n",
    "\n",
    "    test_acc = np.mean([test_preds[i]==y_test[i] for i in range(len(y_test))])\n",
    "    print(f\"\\nFinal Multi-Class Test Accuracy: {float(test_acc)}\")\n",
    "\n",
    "    return models, (X_train_pca, X_test_pca), test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb414c63-d7e9-4029-9e78-1e45039016ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def show_image_with_prediction(X_test, y_test, pred_labels, index=0):\n",
    "#     \"\"\"\n",
    "#     X_test: original shape (N, 784)\n",
    "#     y_test: true digit labels\n",
    "#     pred_labels: array of predicted labels from your model\n",
    "#     index: which test image to show\n",
    "#     \"\"\"\n",
    "#     img = X_test[index].reshape(28,28)\n",
    "#     true_label = y_test[index]\n",
    "#     pred_label = pred_labels[index]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.title(f\"True: {true_label}, Pred: {pred_label}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade94fec-3999-454e-bd68-af263a71c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_test_results(X_test_original, y_test, predictions, start_index=50, end_index=70):\n",
    "    \"\"\"\n",
    "    Visualize test results in a grid, showing the images, predicted labels,\n",
    "    and ground truth labels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_test_original : np.ndarray\n",
    "        The original test images you want to display, shape (N, 784) or (N, 28, 28).\n",
    "        If (N, 784), it will be reshaped to 28x28 for plotting.\n",
    "    y_test : np.ndarray\n",
    "        True labels of the test images, shape (N,).\n",
    "    predictions : np.ndarray\n",
    "        The predicted labels for the test images, shape (N,).\n",
    "    start_index : int, optional\n",
    "        The starting index of the images you want to visualize.\n",
    "    end_index : int, optional\n",
    "        The ending index (non-inclusive) of the images you want to visualize.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of rows and columns for the grid\n",
    "    num_images = end_index - start_index\n",
    "    rows = int(np.ceil(num_images / 5))  # show 5 images per row\n",
    "    cols = 5\n",
    "\n",
    "    # Create a figure\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.flatten()  # Flatten axes array for easier iteration\n",
    "\n",
    "    # Iterate through the specified range\n",
    "    for idx, ax in zip(range(start_index, end_index), axes):\n",
    "        # Get the predicted and true labels\n",
    "        predicted_digit = predictions[idx]\n",
    "        true_digit = y_test[idx]\n",
    "\n",
    "        # Get the image (reshape if necessary)\n",
    "        # If X_test_original is (N, 784), reshape to (28, 28)\n",
    "        img = X_test_original[idx].reshape(28, 28) if X_test_original[idx].size == 784 else X_test_original[idx]\n",
    "\n",
    "        # Determine correctness\n",
    "        if predicted_digit == true_digit:\n",
    "            status = \"correct ✔️\"\n",
    "        else:\n",
    "            status = \"wrong ✖️\"\n",
    "        \n",
    "        # Plot the image\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Pred: {predicted_digit}, True: {true_digit}\\n{status}\")\n",
    "        ax.axis(\"off\")  # Hide axes for cleaner visuals\n",
    "\n",
    "    # Turn off any leftover subplots if #images not multiple of 5\n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed09d91-598b-41ee-8c32-032bd0d73016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2000, 784) Test shape: (500, 784)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def main():\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = load_mnist_data(N_samples=2500, test_size=0.2)\n",
    "    print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "    models, (X_train_pca, X_test_pca), test_preds = train_ova_iterative(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        n_p=3, n_q=2,\n",
    "        pca_dims=15,\n",
    "        max_samples=400,\n",
    "        z_bound=0.5\n",
    "    )\n",
    "    # show_image_with_prediction(X_test, y_test, test_preds, index=25)\n",
    "    visualize_test_results(\n",
    "        X_test_original=X_test, \n",
    "        y_test=y_test, \n",
    "        predictions=test_preds,\n",
    "        start_index=50,\n",
    "        end_index=70\n",
    "    )\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37e6c5-3d5e-4c08-869a-325dcdc07ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop timer\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Total Time: {training_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.4",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
