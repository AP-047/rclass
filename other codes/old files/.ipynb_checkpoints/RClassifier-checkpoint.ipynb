{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0f260a-39de-40b3-88e4-b86ec9388c0b",
   "metadata": {},
   "source": [
    "üçÅ Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9d1051-7755-406d-add7-6d75c6b80251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28), y_train shape: (60000,)\n",
      "x_train_flat shape: (60000, 784), y_train shape: (60000,)\n",
      "x_train_subset shape: (1000, 784)\n",
      "x_train_pca shape: (1000, 77)\n",
      "variance = 0.9022469938012279\n",
      "x_train_norm shape: (1000, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Import\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# 1. Flatten\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "print(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# 2. Subsets\n",
    "subset_size = 1000\n",
    "x_train_subset = x_train_flat[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "print(f\"x_train_subset shape: {x_train_subset.shape}\")\n",
    "\n",
    "# 3. PCA\n",
    "n_components = 77\n",
    "pca = PCA(n_components=n_components)\n",
    "x_train_pca = pca.fit_transform(x_train_subset)\n",
    "print(f\"x_train_pca shape: {x_train_pca.shape}\")\n",
    "variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"variance = {variance}\")  # Verify how much variance is retained\n",
    "\n",
    "# 4. Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_norm = scaler.fit_transform(x_train_pca)\n",
    "print(f\"x_train_norm shape: {x_train_norm.shape}\")\n",
    "x_train_norm.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bce02-b9ac-4a1a-8503-8b77fc5478c4",
   "metadata": {},
   "source": [
    "üçÅ Check Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a048f795-7498-48bf-8d2e-fbdd77af7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing directory: /home/ajay2425/rclass/models/\n",
      "Directory already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to your existing directory\n",
    "models_dir = \"/home/ajay2425/rclass/models/\"\n",
    "print(f\"Using existing directory: {models_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(models_dir):\n",
    "    print(\"Directory already exists.\")\n",
    "else:\n",
    "    print(\"Directory does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99bef8-0fe1-4081-bced-104b53ea8bd0",
   "metadata": {},
   "source": [
    "üçÅ Multi-Indices Generation (Polynomials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0d412d-4778-442c-b1b3-2eeeb0d5a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3081\n"
     ]
    }
   ],
   "source": [
    "def r_multi_indices(n, d):\n",
    "    if n == 1:\n",
    "        yield (d,)\n",
    "    else:\n",
    "        for k in range(d + 1):\n",
    "            for c in r_multi_indices(n - 1, k):\n",
    "                yield (d - k, *c)\n",
    "\n",
    "\n",
    "def generate_multi_indices(n, d):\n",
    "    from itertools import chain\n",
    "    return list(chain(*[list(r_multi_indices(n, _)) for _ in range(d + 1)]))\n",
    "\n",
    "d = 2\n",
    "multi_indices = generate_multi_indices(n_components, d)\n",
    "print(len(multi_indices))\n",
    "# print(f\"Multi-indices: {multi_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa50a29-fe0f-4967-9ca8-17ef970b7841",
   "metadata": {},
   "source": [
    "üçÅ Construct G(x) and H(x) Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b1d0755-426d-4e69-85a8-c5340a017154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_G_H_matrices(x_train_norm, n, d):\n",
    "    num_data_points = x_train_norm.shape[0]\n",
    "    multi_indices = generate_multi_indices(n, d)\n",
    "    num_coefficients = len(multi_indices)\n",
    "\n",
    "    # Initialize G and H matrices\n",
    "    G = []\n",
    "    H = []\n",
    "\n",
    "    # Construct G and H using multi-indices\n",
    "    for i in range(num_data_points):\n",
    "        G_row = []\n",
    "        H_row = []\n",
    "        for idx in multi_indices:\n",
    "            term = np.prod([x_train_norm[i, k] ** idx[k] for k in range(n)])\n",
    "            G_row.append(term)\n",
    "            H_row.append(term)\n",
    "        G.append(G_row)\n",
    "        H.append(H_row)\n",
    "    \n",
    "    return G, H, multi_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0425a514-99a6-48c8-bdab-5938833c64f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G shape: 1000 3081\n",
      "H shape: 1000 3081\n"
     ]
    }
   ],
   "source": [
    "G, H, _ = construct_G_H_matrices(x_train_norm, n_components, d)\n",
    "print(\"G shape:\", len(G), len(G[0]))\n",
    "print(\"H shape:\", len(H), len(H[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b612615-577d-4672-9d4b-e59ac09d2d7f",
   "metadata": {},
   "source": [
    "üçÅ Problem Setup & Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e0d36a-c516-4bd8-8be2-4e7459a2c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.numerical.mip import MixedIntegerLinearProgram\n",
    "\n",
    "# 1. Initialize the problem (Minimization problem)\n",
    "p = MixedIntegerLinearProgram(maximization=False, solver=\"GLPK\")\n",
    "\n",
    "# 3. Define coefficients\n",
    "num_coefficients = len(multi_indices)\n",
    "\n",
    "# 2. Create variables\n",
    "vars = p.new_variable(real=True)  # Real-valued variables\n",
    "theta = vars[\"theta\"]  # Œ∏ - error bound to minimize\n",
    "alpha = [vars[f\"a{j}\"] for j in range(num_coefficients)]  # Œ± coefficients\n",
    "beta = [vars[f\"b{j}\"] for j in range(num_coefficients)]   # Œ≤ coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b969c-c87f-44a6-b6ef-42ee34a5b0c1",
   "metadata": {},
   "source": [
    "üçÅ Feasibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad9fc628-31a0-44d2-8019-52861b8559c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G shape: 1000 3081\n",
      "H shape: 1000 3081\n"
     ]
    }
   ],
   "source": [
    "from sage.numerical.mip import MixedIntegerLinearProgram\n",
    "import numpy as np\n",
    "\n",
    "def check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary, n_components):\n",
    "    # Parameters\n",
    "    num_data_points = x_train_norm.shape[0]\n",
    "    num_coefficients = len(multi_indices)\n",
    "    delta = 1e-6  # Avoid zero denominator\n",
    "\n",
    "    # Construct G and H matrices\n",
    "    d = 2\n",
    "    G, H, _ = construct_G_H_matrices(x_train_norm, n_components, d)\n",
    "\n",
    "    # Define constraints and optimization\n",
    "    p = MixedIntegerLinearProgram(maximization=False)\n",
    "    vars = p.new_variable(real=True)\n",
    "\n",
    "    # Variables\n",
    "    theta = vars[\"theta\"]\n",
    "    alpha = [vars[f\"a{j}\"] for j in range(num_coefficients)]\n",
    "    beta = [vars[f\"b{j}\"] for j in range(num_coefficients)]\n",
    "\n",
    "    # Add Constraints (3)\n",
    "    for i in range(num_data_points):\n",
    "        #1 Upper Bound Constraint\n",
    "        f_minus_z = y_binary[i] - z\n",
    "        p.add_constraint(\n",
    "            -sum(alpha[j] * G[i][j] for j in range(num_coefficients)) +\n",
    "            f_minus_z * sum(beta[j] * H[i][j] for j in range(num_coefficients)) -\n",
    "            theta <= 0\n",
    "        )\n",
    "        #2 Lower Bound Constraint\n",
    "        f_plus_z = y_binary[i] + z\n",
    "        p.add_constraint(\n",
    "            sum(alpha[j] * G[i][j] for j in range(num_coefficients)) -\n",
    "            f_plus_z * sum(beta[j] * H[i][j] for j in range(num_coefficients)) -\n",
    "            theta <= 0\n",
    "        )\n",
    "        #3 Positivity Constraint for Œ≤\n",
    "        p.add_constraint(\n",
    "            sum(beta[j] * H[i][j] for j in range(num_coefficients)) >= delta\n",
    "        )\n",
    "\n",
    "    # Objective: Minimize Œ∏\n",
    "    p.set_objective(theta)\n",
    "\n",
    "    # Solve the problem\n",
    "    try:\n",
    "        p.solve()\n",
    "        optimal_alpha = [p.get_values(alpha[j]) for j in range(num_coefficients)]\n",
    "        optimal_beta = [p.get_values(beta[j]) for j in range(num_coefficients)]\n",
    "        optimal_theta = p.get_values(theta)\n",
    "        return True, optimal_alpha, optimal_beta, optimal_theta\n",
    "    except Exception as e:\n",
    "        return False, None, None, None\n",
    "\n",
    "print(\"G shape:\", len(G), len(G[0]))\n",
    "print(\"H shape:\", len(H), len(H[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baf12b34-957a-479e-be2e-37831ca0bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sage.numerical.mip import MixedIntegerLinearProgram\n",
    "# import numpy as np\n",
    "\n",
    "# z = 250\n",
    "\n",
    "# # Parameters\n",
    "# num_data_points = x_train_norm.shape[0]\n",
    "# num_coefficients = len(multi_indices)\n",
    "# delta = 1e-6  # Avoid zero denominator\n",
    "\n",
    "# # Construct G and H matrices\n",
    "# d = 2\n",
    "# M, N, _ = construct_G_H_matrices(x_train_norm, n_components, d)\n",
    "\n",
    "# # Define constraints and optimization\n",
    "# p = MixedIntegerLinearProgram(maximization=False)\n",
    "# vars = p.new_variable(real=True)\n",
    "\n",
    "# # Variables\n",
    "# theta = vars[\"theta\"]\n",
    "# alpha = [vars[f\"a{j}\"] for j in range(num_coefficients)]\n",
    "# beta = [vars[f\"b{j}\"] for j in range(num_coefficients)]\n",
    "\n",
    "# # Add Constraints (3)\n",
    "# for i in range(num_data_points):\n",
    "#     #1 Upper Bound Constraint\n",
    "#     f_minus_z = y_binary[i] - z\n",
    "#     p.add_constraint(\n",
    "#         -sum(alpha[j] * M[i][j] for j in range(num_coefficients)) +\n",
    "#         f_minus_z * sum(beta[j] * N[i][j] for j in range(num_coefficients)) -\n",
    "#         theta <= 0\n",
    "#     )\n",
    "#     #2 Lower Bound Constraint\n",
    "#     f_plus_z = y_binary[i] + z\n",
    "#     p.add_constraint(\n",
    "#         sum(alpha[j] * M[i][j] for j in range(num_coefficients)) -\n",
    "#         f_plus_z * sum(beta[j] * N[i][j] for j in range(num_coefficients)) -\n",
    "#         theta <= 0\n",
    "#     )\n",
    "#     #3 Positivity Constraint for Œ≤\n",
    "#     p.add_constraint(\n",
    "#         sum(beta[j] * N[i][j] for j in range(num_coefficients)) >= delta\n",
    "#     )\n",
    "\n",
    "# print(\"M shape:\", len(M), len(M[0]))\n",
    "# print(\"N shape:\", len(N), len(N[0]))\n",
    "# print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25671fa7-1ab3-418d-96d3-844071f25f8c",
   "metadata": {},
   "source": [
    "üçÅ Bisection Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dacda36-8f70-480b-b40e-a0a48ba26a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_loop(x_train_norm, y_binary, uL, uH, precision, n_components):\n",
    "    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n",
    "    z_values = []\n",
    "\n",
    "    while uH - uL > precision:\n",
    "        z = (uL + uH) / 2\n",
    "        z_values.append(z)\n",
    "\n",
    "        # Feasibility Check\n",
    "        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(\n",
    "            z, x_train_norm, y_binary, n_components\n",
    "        )\n",
    "\n",
    "        # Update bounds based on feasibility\n",
    "        if feasible:\n",
    "            uH = z\n",
    "            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n",
    "        else:\n",
    "            uL = z\n",
    "\n",
    "    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a7367-02fc-4e8a-8e00-a92566f4255b",
   "metadata": {},
   "source": [
    "üçÅ Optimization for all 10 Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b67f186d-2164-40c7-bf52-65290b6351c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for digit 0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m  \u001b[38;5;66;03m# Precision threshold\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Bisection loop\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values \u001b[38;5;241m=\u001b[39m \u001b[43mbisection_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDigit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdigit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Optimal z = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimal_z\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m, in \u001b[0;36mbisection_loop\u001b[0;34m(x_train_norm, y_binary, uL, uH, precision, n_components)\u001b[0m\n\u001b[1;32m      7\u001b[0m z_values\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Feasibility Check\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m feasible, alpha_coefficients, beta_coefficients, theta \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_feasibility_and_compute_coefficients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Update bounds based on feasibility\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feasible:\n",
      "Cell \u001b[0;32mIn[18], line 28\u001b[0m, in \u001b[0;36mcheck_feasibility_and_compute_coefficients\u001b[0;34m(z, x_train_norm, y_binary, n_components)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_data_points):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#1 Upper Bound Constraint\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     f_minus_z \u001b[38;5;241m=\u001b[39m y_binary[i] \u001b[38;5;241m-\u001b[39m z\n\u001b[1;32m     27\u001b[0m     p\u001b[38;5;241m.\u001b[39madd_constraint(\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_coefficients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     29\u001b[0m         f_minus_z \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(beta[j] \u001b[38;5;241m*\u001b[39m H[i][j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_coefficients)) \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     30\u001b[0m         theta \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#2 Lower Bound Constraint\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     f_plus_z \u001b[38;5;241m=\u001b[39m y_binary[i] \u001b[38;5;241m+\u001b[39m z\n",
      "Cell \u001b[0;32mIn[18], line 28\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_data_points):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#1 Upper Bound Constraint\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     f_minus_z \u001b[38;5;241m=\u001b[39m y_binary[i] \u001b[38;5;241m-\u001b[39m z\n\u001b[1;32m     27\u001b[0m     p\u001b[38;5;241m.\u001b[39madd_constraint(\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(alpha[j] \u001b[38;5;241m*\u001b[39m G[i][j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_coefficients)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     29\u001b[0m         f_minus_z \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(beta[j] \u001b[38;5;241m*\u001b[39m H[i][j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_coefficients)) \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     30\u001b[0m         theta \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#2 Lower Bound Constraint\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     f_plus_z \u001b[38;5;241m=\u001b[39m y_binary[i] \u001b[38;5;241m+\u001b[39m z\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for digit in range(10):\n",
    "    print(f\"Training classifier for digit {digit}...\")\n",
    "\n",
    "    # Binary labels for one-vs-all classification\n",
    "    y_binary = (y_train_subset == digit).astype(float)\n",
    "\n",
    "    # Scale binary labels (2-Y, 4-N)\n",
    "    y_binary = np.where(y_binary == 1, 4, 2)\n",
    "\n",
    "    # Bisection parameters\n",
    "    uL = 0  # Lower bound\n",
    "    uH = 500  # Upper bound\n",
    "    precision = 1e-6  # Precision threshold\n",
    "\n",
    "    # Bisection loop\n",
    "    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(\n",
    "        x_train_norm, y_binary, uL, uH, precision, n_components\n",
    "    )\n",
    "\n",
    "    # Results\n",
    "    print(f\"Digit {digit}: Optimal z = {optimal_z}\")\n",
    "    print(f\"Alpha: {optimal_alpha}\")\n",
    "    print(f\"Beta: {optimal_beta}\")\n",
    "    print(f\"Theta: {optimal_theta}\")\n",
    "\n",
    "    # Save the model\n",
    "    model = {\n",
    "        \"alpha\": optimal_alpha,\n",
    "        \"beta\": optimal_beta,\n",
    "        \"theta\": optimal_theta,\n",
    "        \"n_components\": n_components\n",
    "    }\n",
    "    with open(f\"{models_dir}/classifier_{digit}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print(f\"Model saved for digit {digit} at {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028ecf5-08c6-4750-b751-9aaad34aab1d",
   "metadata": {},
   "source": [
    "üçÅ Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64882b02-6450-4da1-bd99-d73accf3059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# Multi-Indices\n",
    "# def generate_multi_indices(n, d):\n",
    "#     indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n",
    "#     return indices\n",
    "\n",
    "# def construct_polynomial(x, coefficients, indices):\n",
    "#     polynomial_value = 0\n",
    "#     for coeff, idx in zip(coefficients, indices):\n",
    "#         term = coeff * np.prod([x[i] ** idx[i] for i in range(len(x))])\n",
    "#         polynomial_value += term\n",
    "#     return polynomial_value\n",
    "\n",
    "# def rational_function(x, alpha, beta, n, d):\n",
    "#     indices = generate_multi_indices(n, d)\n",
    "\n",
    "#     # Compute numerator and denominator\n",
    "#     numerator = construct_polynomial(x, alpha, indices)\n",
    "#     denominator = construct_polynomial(x, beta, indices)\n",
    "\n",
    "#     # Avoid division by zero\n",
    "#     if abs(denominator) < 1e-8:\n",
    "#         denominator = 1e-8\n",
    "\n",
    "#     return numerator / denominator\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Import and Preprocess Test Data\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Flatten\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Subsets\n",
    "subset_size = 10000\n",
    "x_test_subset = x_test[:subset_size]\n",
    "y_test_subset = y_test[:subset_size]\n",
    "print(f\"x_test_subset shape: {x_test_subset.shape}\")\n",
    "\n",
    "# PCA\n",
    "n_components = 77\n",
    "pca = PCA(n_components=n_components)\n",
    "x_test_pca = pca.fit_transform(x_test_subset)\n",
    "print(f\"x_test_pca shape: {x_test_pca.shape}\")\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_test_norm = scaler.fit_transform(x_test_pca)\n",
    "print(f\"x_test_norm shape: {x_test_norm.shape}\")\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Directory Setup for Models\n",
    "models_dir = \"/home/ajayp/RClass/models/\"\n",
    "if not os.path.exists(models_dir):\n",
    "    raise FileNotFoundError(f\"Models directory not found at: {models_dir}\")\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Load Saved Models and Test\n",
    "for digit in range(10):\n",
    "    \n",
    "    # Load the model for each digit\n",
    "    with open(f\"{models_dir}/classifier_{digit}.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    alpha = model[\"alpha\"]\n",
    "    beta = model[\"beta\"]\n",
    "    theta = model[\"theta\"]\n",
    "\n",
    "    # # Evaluate predictions using Polynomial Approach\n",
    "    # y_predicted = [\n",
    "    #     rational_function(x, alpha, beta) for x in x_test_norm\n",
    "    # ]\n",
    "\n",
    "    Evaluate predictions using Multi-Indices Approach\n",
    "    n = 2\n",
    "    d = 2\n",
    "    y_predicted = [\n",
    "        rational_function(x, alpha, beta, n, d) for x in x_test_norm\n",
    "    ]\n",
    "\n",
    "    # Binary classification based on predictions\n",
    "    y_pred_binary = np.array(y_predicted) < 3\n",
    "    y_true_binary = y_test_subset == digit\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(y_pred_binary == y_true_binary)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Overall Accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Plot Accuracies for Each Digit\n",
    "plt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\n",
    "plt.xlabel(\"Digits\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy for Each Digit\")\n",
    "plt.xticks(range(10))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SageMath)",
   "language": "python",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
